# LLM utils

## LoRA fine tuning server

**Install**

```bash
pip install git+https://github.com/erwinliyh/kylis_kit@main[llm]
```

Install flash attantion (optional):

```bash
conda install -c nvidia cuda-python # (optional)
pip install flash_attn
```

**Usage**

```bash
kkit-lora-server -h
```
